import os
from pathlib import Path

import pandas as pd
from androguard.misc import AnalyzeAPK
from nltk import WordNetLemmatizer, word_tokenize
from nltk.corpus import stopwords


from gensim.models import Doc2Vec
import joblib


english_stopwords = set(stopwords.words('english'))
# Adding custom stopwords
custom_stopwords = {'activity', 'service', 'android', 'intent', 'application'}
english_stopwords.update(custom_stopwords)

lemmatizer = WordNetLemmatizer()

def preprocess(text):
    # Tokenize and convert to lower case
    words = word_tokenize(text.lower())
    # Remove stop words and apply lemmatization, only keep alphanumeric words
    filtered_words = [lemmatizer.lemmatize(w) for w in words if w.isalnum() and not w in english_stopwords]
    return filtered_words

def extract_features_from_apk(apk_path):
    try:
        a, d, dx = AnalyzeAPK(apk_path)
        permissions = a.get_permissions()
        # Xử lý EncodedMethod trong api_calls
        api_calls = []
        for method in dx.find_methods():
            try:
                api_calls.append(method.get_method())
            except AttributeError:
                # Xử lý trường hợp EncodedMethod không có phương thức get_method()
                pass

        # Chuyển các dữ liệu không phải chuỗi thành chuỗi
        permissions = [str(p) for p in permissions]
        api_calls = [str(ac) for ac in api_calls]

        # Kết hợp tất cả các đặc trưng thành một chuỗi văn bản
        all_features = ' '.join(permissions  + api_calls)
        return all_features
    except Exception as e:
        print(f"Error processing APK file: {apk_path}. Error: {str(e)}")
        return None

def load_doc2vec_model(model_path):
    return Doc2Vec.load(model_path)

def vectorize_text(model, text):
    processed_text = preprocess(text)
    return model.infer_vector(processed_text)

def predict_apk_files(apk_directory, doc2vec_model, rf_model):
    malware_count = 0
    total_files = 0
    benign_count = 0
    for apk_file in os.listdir(apk_directory):
        if apk_file.endswith(".apk"):
            apk_path = os.path.join(apk_directory, apk_file)
            features_text = extract_features_from_apk(apk_path)
            if features_text:
                vector = vectorize_text(doc2vec_model, features_text)
                prediction = rf_model.predict([vector])
                if prediction[0] == 'MALWARE':
                    malware_count += 1
                else:
                    benign_count += 1
                total_files += 1
                print(f"Processed {total_files} files. Malware count: {malware_count}")
    return (malware_count, benign_count)

# Đường dẫn tới thư mục chứa các file APK
apk_directory = Path("./apk_test")

# Load mô hình Doc2Vec đã huấn luyện
doc2vec_model = Doc2Vec.load("./apk_doc2vec_model1.model")

# Load mô hình Random Forest đã được huấn luyện
rf_model = joblib.load("./_random_forest_model2.pkl")

# Đếm số lượng malware trong thư mục chứa các file APK
num_malware = predict_apk_files(apk_directory, doc2vec_model, rf_model)

print("Số lượng file APK malware,benign:", num_malware)
